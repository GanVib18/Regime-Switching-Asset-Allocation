# -*- coding: utf-8 -*-
"""allocation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_nuVpLR40psAnwhDTRvr6ovm0OdnXoSj

## Asset Allocation Insights

### Install Dependencies
"""

!pip install hmmlearn

"""### Import Libraries"""

import os
import warnings
warnings.filterwarnings("ignore")

import joblib
import numpy as np
import pandas as pd
from hmmlearn.hmm import GaussianHMM
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import matplotlib.dates as mdates
import seaborn as sns
from datetime import datetime

"""### Configuration"""

INPUT_DATA      = "/content/data_with_regimes.csv"
INPUT_MODEL     = "/content/model_hmm.pkl"
OUTPUT_DIR      = "/content"

# Forward-looking horizon (days) — Step 11
FORWARD_DAYS    = 30

# Crisis regime index (always 2 after semantic relabelling in Phase 2)
CRISIS_REGIME   = 2

# Train cutoff — regime characteristics computed on training data only
TRAIN_END       = "2023-12-31"

# ── Regime display settings (must match Phase 2) ──────────────────────────
REGIME_COLORS   = {0: "#2ECC71", 1: "#F39C12", 2: "#E74C3C"}
REGIME_LABELS   = {0: "Low-Vol (Bull)",
                   1: "Medium-Vol (Normal)",
                   2: "High-Vol (Crisis)"}

# ── ETF definitions — must match what data_prep.py downloaded ─────────────
ETF_CONFIG = {
    "XIU.TO": "iShares S&P/TSX 60 (XIU)",
    "VFV.TO": "Vanguard S&P 500 Index (VFV)",
    "XEF.TO": "iShares MSCI EAFE (XEF)",
    "XBB.TO": "iShares Cdn Bond (XBB)",
    "CGL-C.TO": "iShares Gold Bullion (CGL)",
}
EQUITY_TICKERS  = ["XIU.TO", "VFV.TO", "XEF.TO"]
BOND_TICKERS    = ["XBB.TO"]
GOLD_TICKERS    = ["CGL-C.TO"]       # gold treated as defensive/alternative

"""### Regime-based target weights"""

# Format: {ticker: weight}  — weights must sum to 1.0 per regime
TARGET_WEIGHTS = {
    0: {   # Low-Vol (Bull) — 70% equity, 20% bond, 10% gold
        "XIU.TO":   0.30,
        "VFV.TO":   0.25,
        "XEF.TO":   0.15,
        "XBB.TO":   0.20,
        "CGL-C.TO": 0.10,
    },
    1: {   # Medium-Vol (Normal) — 60% equity, 28% bond, 12% gold
        "XIU.TO":   0.25,
        "VFV.TO":   0.20,
        "XEF.TO":   0.15,
        "XBB.TO":   0.28,
        "CGL-C.TO": 0.12,
    },
    2: {   # High-Vol (Crisis) — 40% equity, 40% bond, 20% gold
        "XIU.TO":   0.15,
        "VFV.TO":   0.13,
        "XEF.TO":   0.12,
        "XBB.TO":   0.40,
        "CGL-C.TO": 0.20,
    },
}

"""### Rebalancing parameters"""

REBALANCE_THRESHOLD = 0.05    # only trade if weight drifts >5% from target
BID_ASK_SPREAD      = 0.0008  # 8 bps round-trip transaction cost per trade

# ── Step 15: Backtest parameters ─────────────────────────────────────────
INITIAL_CAPITAL     = 100_000.0   # $100,000 starting portfolio
RISK_FREE_RATE      = 0.02       # 2% annual — Canadian T-bill approximation

# Known stress events for annotations
STRESS_EVENTS = {
    "COVID Crash":     ("2020-02-01", "2020-05-31"),
    "2022 Rate Shock": ("2022-01-01", "2022-12-31"),
    "2018 Q4":         ("2018-10-01", "2018-12-31"),
}

"""### Helper Fn."""

def add_year_grid(ax: plt.Axes) -> None:
    ax.xaxis.set_major_formatter(mdates.DateFormatter("%Y"))
    ax.xaxis.set_major_locator(mdates.YearLocator())
    ax.grid(alpha=0.3)
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)


def pct_fmt(ax: plt.Axes, axis: str = "y") -> None:
    fmt = plt.FuncFormatter(lambda x, _: f"{x:.0%}")
    if axis == "y":
        ax.yaxis.set_major_formatter(fmt)
    else:
        ax.xaxis.set_major_formatter(fmt)


def annotate_stress(ax: plt.Axes, alpha: float = 0.08) -> None:
    """Shade known stress event windows on an axes."""
    for label, (start, end) in STRESS_EVENTS.items():
        ax.axvspan(pd.Timestamp(start), pd.Timestamp(end),
                   alpha=alpha, color="black", zorder=0)


def regime_legend_patches() -> list:
    return [mpatches.Patch(color=REGIME_COLORS[r], label=REGIME_LABELS[r])
            for r in sorted(REGIME_LABELS)]

"""### Load Data & Model"""

print(f"\n[1/8]  Loading data and model ...")

if not os.path.exists(INPUT_DATA):
    raise FileNotFoundError(
        f"Cannot find {INPUT_DATA}.\n"
        "Run baseline_model.py (Phase 2) first."
    )
if not os.path.exists(INPUT_MODEL):
    raise FileNotFoundError(
        f"Cannot find {INPUT_MODEL}.\n"
        "Run baseline_model.py (Phase 2) first."
    )

master = pd.read_csv(INPUT_DATA, index_col="Date", parse_dates=True)
master.sort_index(inplace=True)
print(f"       Data   : {master.shape[0]} rows × {master.shape[1]} cols")
print(f"       Range  : {master.index[0].date()} → {master.index[-1].date()}")

bundle         = joblib.load(INPUT_MODEL)
hmm            = bundle["hmm"]
state_to_regime= bundle["state_to_regime"]
n_regimes      = bundle["n_regimes"]

print(f"       Model  : Gaussian HMM, {n_regimes} regimes loaded")

# Identify return columns
ret_cols = [c for c in master.columns if c.endswith("_Return")]
tickers  = [c.replace("_Return", "") for c in ret_cols]
print(f"       Return columns: {ret_cols}")

"""### Transistion Probability Matrix"""

print("\n[2/8]  Step 10 — Transition Probability Matrix ...")

# Reconstruct the semantically-ordered transition matrix
raw_trans      = hmm.transmat_
ordered_states = sorted(state_to_regime, key=state_to_regime.get)  # low→mid→high
trans_matrix   = np.zeros((n_regimes, n_regimes))
for new_from, old_from in enumerate(ordered_states):
    for new_to, old_to in enumerate(ordered_states):
        trans_matrix[new_from, new_to] = raw_trans[old_from, old_to]

# Normalise rows (should already sum to 1, but floating point safety)
trans_matrix = trans_matrix / trans_matrix.sum(axis=1, keepdims=True)

trans_df = pd.DataFrame(
    trans_matrix,
    index   = [f"From: {REGIME_LABELS[r]}" for r in range(n_regimes)],
    columns = [f"To: {REGIME_LABELS[r]}"   for r in range(n_regimes)],
)

print("\n       Regime Transition Probability Matrix:")
print(trans_df.to_string())
print()
for r in range(n_regimes):
    stay  = trans_matrix[r, r]
    avg_days = 1 / (1 - stay) if stay < 1 else np.inf
    print(f"       {REGIME_LABELS[r]:<26}: "
          f"P(stay) = {stay:.2%}   Expected duration ≈ {avg_days:.1f} days")

trans_df.to_csv(os.path.join(OUTPUT_DIR, "phase3_transition_analysis.csv"))
print(f"\n       OK - phase3_transition_analysis.csv")

"""### Forward-Looking Crisis Probability"""

print(f"\n[3/8]  Step 11 — Forward-looking crisis probability "
      f"({FORWARD_DAYS}-day horizon) ...")

# For each day t, we have a posterior probability vector π_t = [P(R0), P(R1), P(R2)]
# The probability of being in regime r at t+h is:  π_t @ T^h
# We want P(Crisis at t+30) = (π_t @ T^30)[CRISIS_REGIME]

# Pre-compute T^30 once (matrix exponentiation)
T_power = np.linalg.matrix_power(trans_matrix, FORWARD_DAYS)
print(f"       T^{FORWARD_DAYS} (transition matrix raised to {FORWARD_DAYS}):")
for r in range(n_regimes):
    row_str = "  ".join(f"{T_power[r, c]:.4f}" for c in range(n_regimes))
    print(f"         {REGIME_LABELS[r][:15]:<15}: [{row_str}]")

# Extract posterior probability columns
p_cols = [f"P_Regime{r}" for r in range(n_regimes)]
missing_p = [c for c in p_cols if c not in master.columns]
if missing_p:
    raise KeyError(
        f"Posterior probability columns not found in data: {missing_p}\n"
        "Ensure baseline_model.py ran correctly and saved P_Regime columns."
    )

posterior_matrix = master[p_cols].fillna(0).values  # shape (T, n_regimes)

# Forward probability: π_t @ T^h  →  take the crisis column
forward_probs     = posterior_matrix @ T_power        # shape (T, n_regimes)
crisis_prob_30d   = forward_probs[:, CRISIS_REGIME]   # shape (T,)

# Also compute 1-day and 7-day forward for richer signal output
T_1  = np.linalg.matrix_power(trans_matrix, 1)
T_7  = np.linalg.matrix_power(trans_matrix, 7)
crisis_prob_1d  = (posterior_matrix @ T_1)[:, CRISIS_REGIME]
crisis_prob_7d  = (posterior_matrix @ T_7)[:, CRISIS_REGIME]

signals = pd.DataFrame({
    "Regime":               master["Regime"],
    "P_Crisis_1d":          crisis_prob_1d,
    "P_Crisis_7d":          crisis_prob_7d,
    "P_Crisis_30d":         crisis_prob_30d,
    "P_Bull_30d":           forward_probs[:, 0],
    "P_Normal_30d":         forward_probs[:, 1],
}, index=master.index)

signals.to_csv(os.path.join(OUTPUT_DIR, "phase3_forward_signals.csv"))
print(f"\n       OK - phase3_forward_signals.csv")

# Quick sanity: show signal around COVID crash
covid_window = signals.loc["2020-01-15":"2020-04-30", "P_Crisis_30d"]
if not covid_window.empty:
    peak_date = covid_window.idxmax()
    print(f"\n       COVID 30-day crisis probability peak: "
          f"{covid_window.max():.1%} on {peak_date.date()}")

"""### Regime Characteristics"""

print("\n[4/8]  Step 12 — Regime Characteristics (training set only) ...")

train_data = master[master.index <= TRAIN_END].copy()

char_rows = []
for r in range(n_regimes):
    mask   = train_data["Regime"] == r
    subset = train_data.loc[mask]
    n_days = int(mask.sum())

    if n_days == 0:
        continue

    row = {
        "Regime":       r,
        "Label":        REGIME_LABELS[r],
        "N_Days":       n_days,
        "Pct_Time":     n_days / len(train_data),
    }

    # Per-ETF return statistics
    for col in ret_cols:
        ticker = col.replace("_Return", "")
        if col in subset.columns:
            daily_ret = subset[col].dropna()
            row[f"{ticker}_MeanDailyRet"] = daily_ret.mean()
            row[f"{ticker}_AnnRet"]       = daily_ret.mean() * 252
            row[f"{ticker}_AnnVol"]       = daily_ret.std() * np.sqrt(252)
            row[f"{ticker}_Sharpe"]       = (
                (daily_ret.mean() * 252 - RISK_FREE_RATE) /
                (daily_ret.std() * np.sqrt(252))
                if daily_ret.std() > 0 else np.nan
            )

    # Aggregate equity return (equal-weight average of equity ETFs)
    eq_ret_cols  = [f"{t}_Return" for t in EQUITY_TICKERS if f"{t}_Return" in subset.columns]
    bnd_ret_cols = [f"{t}_Return" for t in BOND_TICKERS   if f"{t}_Return" in subset.columns]

    if eq_ret_cols:
        avg_eq = subset[eq_ret_cols].mean(axis=1)
        row["Equity_AnnRet"] = avg_eq.mean() * 252
        row["Equity_AnnVol"] = avg_eq.std()  * np.sqrt(252)

    if bnd_ret_cols:
        avg_bnd = subset[bnd_ret_cols].mean(axis=1)
        row["Bond_AnnRet"] = avg_bnd.mean() * 252
        row["Bond_AnnVol"] = avg_bnd.std()  * np.sqrt(252)

    # Equity-bond correlation in this regime
    if eq_ret_cols and bnd_ret_cols:
        eq_series  = subset[eq_ret_cols].mean(axis=1)
        bnd_series = subset[bnd_ret_cols].mean(axis=1)
        row["EQ_Bond_Corr"] = eq_series.corr(bnd_series)

    # Average market vol in this regime
    if "Market_RolVol20" in subset.columns:
        row["Avg_Market_Vol"] = subset["Market_RolVol20"].mean()

    char_rows.append(row)

char_df = pd.DataFrame(char_rows).set_index("Regime")
char_df.to_csv(os.path.join(OUTPUT_DIR, "phase3_regime_characteristics.csv"))

print(f"\n       {'Regime':<26}  {'Days':>5}  {'%Time':>6}  "
      f"{'Mkt Vol':>7}  {'EQ Ret':>7}  {'Bond Ret':>8}  {'EQ-Bond Corr':>12}")
print("       " + "-" * 80)
for r in range(n_regimes):
    if r not in char_df.index:
        continue
    row = char_df.loc[r]
    print(f"       {REGIME_LABELS[r]:<26}  "
          f"{row['N_Days']:>5}  "
          f"{row['Pct_Time']:>6.1%}  "
          f"{row.get('Avg_Market_Vol', np.nan):>7.1%}  "
          f"{row.get('Equity_AnnRet', np.nan):>+7.1%}  "
          f"{row.get('Bond_AnnRet', np.nan):>+8.1%}  "
          f"{row.get('EQ_Bond_Corr', np.nan):>12.4f}")

print(f"\n       OK - phase3_regime_characteristics.csv")

"""### Portfolio Backtest"""

print("\n[5/8]  Steps 13-15 — Portfolio Backtest ...")

all_tickers = list(ETF_CONFIG.keys())

# Verify all return columns are present
missing_ret = [f"{t}_Return" for t in all_tickers
               if f"{t}_Return" not in master.columns]
if missing_ret:
    raise KeyError(
        f"Return columns missing from data_with_regimes.csv: {missing_ret}\n"
        "Check that data_prep.py used the same ETF tickers."
    )

# ── Build regime series ───────────────────────────────────────────────────
# Use posterior-weighted regime: rather than hard-classifying, blend target
# weights by regime probability — this is the "soft allocation" approach
# mentioned in the plan's interview Q&A section.
# Formula: w_t = Σ_r P(regime=r at t) * TargetWeights[r]

def compute_soft_weights(posterior_row: np.ndarray) -> dict:
    """Compute probability-weighted target allocation for one day."""
    weights = {t: 0.0 for t in all_tickers}
    for r in range(n_regimes):
        p = posterior_row[r]
        for ticker, w in TARGET_WEIGHTS[r].items():
            weights[ticker] += p * w
    # Normalise to ensure exact sum=1 (floating point safety)
    total = sum(weights.values())
    return {t: w / total for t, w in weights.items()}


def compute_hard_weights(regime: int) -> dict:
    """Hard allocation based on current regime label."""
    return TARGET_WEIGHTS.get(int(regime), TARGET_WEIGHTS[1])


# ── Benchmark: static 60/40 ───────────────────────────────────────────────
# Equal-weight equities summing to 60%, equal-weight bonds summing to 40%
# (Gold excluded from benchmark for a clean comparison)
N_EQ  = len(EQUITY_TICKERS)
N_BND = len(BOND_TICKERS)
BENCHMARK_WEIGHTS = {t: 0.60 / N_EQ  for t in EQUITY_TICKERS}
BENCHMARK_WEIGHTS.update({t: 0.40 / N_BND for t in BOND_TICKERS})
for t in GOLD_TICKERS:
    BENCHMARK_WEIGHTS[t] = 0.0

# ── Initialise backtest state ─────────────────────────────────────────────
bt_dates        = master.index
n_days          = len(bt_dates)

# Portfolio value tracking
portfolio_values   = np.zeros(n_days)
benchmark_values   = np.zeros(n_days)

# Current holdings: value allocated to each ETF
holdings           = {}    # {ticker: dollar_value}
bm_holdings        = {}    # benchmark holdings

# Trade log
trade_log = []

# Initialise on day 0
day0_regime = master["Regime"].iloc[0]
if np.isnan(day0_regime):
    day0_regime = 1   # default to Normal if regime unknown

day0_posterior = master[p_cols].iloc[0].fillna(0).values
day0_weights   = compute_soft_weights(day0_posterior)

for ticker in all_tickers:
    holdings[ticker]    = INITIAL_CAPITAL * day0_weights.get(ticker, 0.0)
    bm_holdings[ticker] = INITIAL_CAPITAL * BENCHMARK_WEIGHTS.get(ticker, 0.0)

portfolio_values[0] = INITIAL_CAPITAL
benchmark_values[0] = INITIAL_CAPITAL

current_weights = day0_weights.copy()
total_costs     = 0.0
n_rebalances    = 0

# ── Main backtest loop ─────────────────────────────────────────────────────
for i in range(1, n_days):
    date      = bt_dates[i]
    prev_date = bt_dates[i - 1]

    # Step 1: Apply today's returns to yesterday's holdings
    pv_today = 0.0
    bm_today = 0.0
    for ticker in all_tickers:
        ret_col = f"{ticker}_Return"
        ret = master.loc[date, ret_col] if ret_col in master.columns else 0.0
        if pd.isna(ret):
            ret = 0.0
        holdings[ticker]    *= (1 + ret)
        bm_holdings[ticker] *= (1 + ret)
        pv_today += holdings[ticker]
        bm_today += bm_holdings[ticker]

    portfolio_values[i] = pv_today
    benchmark_values[i] = bm_today

    # Step 2: Compute today's target weights (soft allocation)
    posterior_today = master[p_cols].iloc[i].fillna(0).values
    target_weights  = compute_soft_weights(posterior_today)

    # Also store regime label for trade log
    regime_today = master["Regime"].iloc[i]
    if pd.isna(regime_today):
        regime_today = 1

    # Step 3: Check if rebalancing needed (any weight drifts >5%)
    actual_weights = {t: holdings[t] / pv_today if pv_today > 0 else 0
                      for t in all_tickers}

    max_drift = max(abs(actual_weights.get(t, 0) - target_weights.get(t, 0))
                    for t in all_tickers)

    if max_drift > REBALANCE_THRESHOLD:
        # Rebalance: compute trades
        cost_this_rebalance = 0.0
        trades = {}
        for ticker in all_tickers:
            target_value  = pv_today * target_weights.get(ticker, 0.0)
            current_value = holdings[ticker]
            trade_value   = abs(target_value - current_value)
            cost          = trade_value * BID_ASK_SPREAD
            cost_this_rebalance += cost
            trades[ticker] = target_value - current_value  # + = buy, - = sell
            holdings[ticker] = target_value - cost / 2     # cost splits buy/sell

        # Deduct total cost from portfolio
        pv_after_cost = sum(holdings.values())
        scale = (pv_today - cost_this_rebalance) / pv_today if pv_today > 0 else 1
        for ticker in all_tickers:
            holdings[ticker] *= scale

        portfolio_values[i]  = sum(holdings.values())
        total_costs         += cost_this_rebalance
        current_weights      = target_weights.copy()
        n_rebalances        += 1

        trade_log.append({
            "Date":         date,
            "Regime":       int(regime_today),
            "Regime_Label": REGIME_LABELS.get(int(regime_today), "Unknown"),
            "Max_Drift":    max_drift,
            "Cost":         cost_this_rebalance,
            **{f"Trade_{t}": trades.get(t, 0.0) for t in all_tickers},
        })

# ── Compile results ───────────────────────────────────────────────────────
portfolio_df = pd.DataFrame({
    "Date":              bt_dates,
    "Portfolio_Value":   portfolio_values,
    "Benchmark_Value":   benchmark_values,
    "Regime":            master["Regime"].values,
    "P_Crisis_30d":      signals["P_Crisis_30d"].values,
}).set_index("Date")

portfolio_df["Portfolio_Return"] = portfolio_df["Portfolio_Value"].pct_change()
portfolio_df["Benchmark_Return"] = portfolio_df["Benchmark_Value"].pct_change()

trade_log_df = pd.DataFrame(trade_log).set_index("Date") if trade_log else pd.DataFrame()

portfolio_df.to_csv(os.path.join(OUTPUT_DIR, "phase4_portfolio_values.csv"))
if not trade_log_df.empty:
    trade_log_df.to_csv(os.path.join(OUTPUT_DIR, "phase4_trade_log.csv"))

print(f"       Backtest complete: {n_days} trading days")
print(f"       Total rebalances : {n_rebalances}")
print(f"       Total costs      : ${total_costs:.2f}")

"""### Performance Metrics"""

print("\n[6/8]  Computing performance metrics ...")


def performance_metrics(values: np.ndarray,
                        rf_annual: float = RISK_FREE_RATE) -> dict:
    """Compute standard performance metrics from a portfolio value series."""
    returns = pd.Series(values).pct_change().dropna()
    if len(returns) == 0:
        return {}

    total_return  = (values[-1] - values[0]) / values[0]
    ann_return    = (1 + total_return) ** (252 / len(returns)) - 1
    ann_vol       = returns.std() * np.sqrt(252)
    sharpe        = (ann_return - rf_annual) / ann_vol if ann_vol > 0 else np.nan

    # Maximum drawdown
    cumulative    = pd.Series(values)
    rolling_max   = cumulative.cummax()
    drawdown      = (cumulative - rolling_max) / rolling_max
    max_dd        = drawdown.min()

    calmar        = ann_return / abs(max_dd) if max_dd != 0 else np.nan
    win_rate      = (returns > 0).mean()

    return {
        "Total_Return":   total_return,
        "Ann_Return":     ann_return,
        "Ann_Vol":        ann_vol,
        "Sharpe_Ratio":   sharpe,
        "Max_Drawdown":   max_dd,
        "Calmar_Ratio":   calmar,
        "Win_Rate":       win_rate,
    }


strat_metrics = performance_metrics(portfolio_values)
bench_metrics = performance_metrics(benchmark_values)

print(f"\n       {'Metric':<20}  {'Strategy':>10}  {'60/40 BH':>10}  {'Difference':>12}")
print("       " + "-" * 58)

metric_display = {
    "Total_Return":  ("Total Return",       "{:>+10.1%}", "{:>+12.1%}"),
    "Ann_Return":    ("Ann. Return",         "{:>+10.1%}", "{:>+12.1%}"),
    "Ann_Vol":       ("Ann. Volatility",     "{:>10.1%}",  "{:>12.1%}"),
    "Sharpe_Ratio":  ("Sharpe Ratio",        "{:>10.3f}",  "{:>12.3f}"),
    "Max_Drawdown":  ("Max Drawdown",        "{:>+10.1%}", "{:>+12.1%}"),
    "Calmar_Ratio":  ("Calmar Ratio",        "{:>10.3f}",  "{:>12.3f}"),
    "Win_Rate":      ("Win Rate",            "{:>10.1%}",  "{:>12.1%}"),
}

results_rows = []
for key, (label, sfmt, dfmt) in metric_display.items():
    s = strat_metrics.get(key, np.nan)
    b = bench_metrics.get(key, np.nan)
    d = s - b if not (np.isnan(s) or np.isnan(b)) else np.nan
    print(f"       {label:<20}  {sfmt.format(s)}  {sfmt.format(b)}  {dfmt.format(d)}")
    results_rows.append({"Metric": label, "Strategy": s, "Benchmark_60_40": b, "Difference": d})

results_df = pd.DataFrame(results_rows)

net_cost_impact = total_costs / portfolio_values[-1]
print(f"\n       Transaction costs: ${total_costs:.2f}  "
      f"({net_cost_impact:.3%} of final portfolio value)")

"""### Charts"""

print("\n[7/8]  Generating charts ...")

# ── Chart 1: Transition Matrix Heatmap ──────────────────────────────────
fig, ax = plt.subplots(figsize=(8, 6))
short_labels = [f"R{r}: {REGIME_LABELS[r][:12]}" for r in range(n_regimes)]
# Use log scale for display since values span many orders of magnitude,
# but show actual percentages in annotations
annot_matrix = np.array([[f"{trans_matrix[r,c]:.2%}" for c in range(n_regimes)]
                          for r in range(n_regimes)])
# Clip near-zero values for colour mapping only
display_matrix = np.clip(trans_matrix, 1e-6, 1.0)
sns.heatmap(display_matrix, annot=annot_matrix, fmt="",
            cmap="YlOrRd",
            xticklabels=short_labels, yticklabels=short_labels,
            linewidths=0.5, annot_kws={"size": 11}, ax=ax,
            vmin=0, vmax=1)
ax.set_title("Regime Transition Probability Matrix\n(Row = From State, Col = To State)",
             fontsize=13, fontweight="bold")
ax.set_xlabel("To Regime")
ax.set_ylabel("From Regime")
plt.tight_layout()
fig.savefig(os.path.join(OUTPUT_DIR, "chart_transition_matrix.png"),
            dpi=150, bbox_inches="tight")
plt.close()
print("       OK - chart_transition_matrix.png")


# ── Chart 2: Forward-Looking Crisis Probability ──────────────────────────
fig, axes = plt.subplots(2, 1, figsize=(14, 8),
                          gridspec_kw={"height_ratios": [1, 2]},
                          sharex=True)

# Top: regime colour bands using axvspan to avoid y-axis corruption
ax0 = axes[0]
for r in range(n_regimes):
    in_regime = False
    start_date = None
    for date, reg in master["Regime"].items():
        if reg == r and not in_regime:
            in_regime = True
            start_date = date
        elif reg != r and in_regime:
            ax0.axvspan(start_date, date,
                        alpha=0.8, color=REGIME_COLORS[r], zorder=0)
            in_regime = False
    if in_regime and start_date is not None:
        ax0.axvspan(start_date, master.index[-1],
                    alpha=0.8, color=REGIME_COLORS[r], zorder=0)
ax0.set_yticks([])
ax0.set_ylabel("Regime", fontsize=9)
ax0.legend(handles=regime_legend_patches(), loc="upper right",
           fontsize=7, ncol=3)
ax0.set_title("30-Day Forward Crisis Probability vs Detected Regimes",
              fontsize=13, fontweight="bold")
annotate_stress(ax0)

# Bottom: forward crisis probability
ax1 = axes[1]
ax1.fill_between(signals.index, signals["P_Crisis_30d"],
                 alpha=0.35, color="#E74C3C", label="P(Crisis in 30 days)")
ax1.plot(signals.index, signals["P_Crisis_30d"],
         color="#E74C3C", linewidth=1.2)
ax1.axhline(0.10, color="gray", linestyle="--", linewidth=1,
            label="10% threshold")
ax1.set_ylabel("Crisis Probability (30-day horizon)")
pct_fmt(ax1)
ax1.set_ylim(0, 1)
ax1.legend(loc="upper right", fontsize=8)
add_year_grid(ax1)
annotate_stress(ax1)

plt.tight_layout()
fig.savefig(os.path.join(OUTPUT_DIR, "chart_forward_crisis_probability.png"),
            dpi=150, bbox_inches="tight")
plt.close()
print("       OK - chart_forward_crisis_probability.png")


# ── Chart 3: Regime Characteristics ─────────────────────────────────────
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
regime_names       = [REGIME_LABELS[r] for r in range(n_regimes)
                      if r in char_df.index]
regime_colors_list = [REGIME_COLORS[r] for r in range(n_regimes)
                      if r in char_df.index]
valid_regimes      = [r for r in range(n_regimes) if r in char_df.index]

# Panel 1: Equity annualised return per regime
eq_rets = [char_df.loc[r, "Equity_AnnRet"] if "Equity_AnnRet" in char_df.columns
           else np.nan for r in valid_regimes]
axes[0].bar(regime_names, eq_rets, color=regime_colors_list, edgecolor="white")
axes[0].axhline(0, color="black", linewidth=0.8)
axes[0].set_title("Equity Ann. Return\nper Regime", fontsize=11, fontweight="bold")
axes[0].set_ylabel("Annualised Return")
pct_fmt(axes[0])

# Panel 2: Market volatility per regime
mkt_vols = [char_df.loc[r, "Avg_Market_Vol"] if "Avg_Market_Vol" in char_df.columns
            else np.nan for r in valid_regimes]
axes[1].bar(regime_names, mkt_vols, color=regime_colors_list, edgecolor="white")
axes[1].set_title("Avg Market Volatility\nper Regime", fontsize=11, fontweight="bold")
axes[1].set_ylabel("Annualised Volatility")
pct_fmt(axes[1])

# Panel 3: Equity-bond correlation per regime
eq_bond = [char_df.loc[r, "EQ_Bond_Corr"] if "EQ_Bond_Corr" in char_df.columns
           else np.nan for r in valid_regimes]
axes[2].bar(regime_names, eq_bond, color=regime_colors_list, edgecolor="white")
axes[2].axhline(0, color="black", linewidth=0.8)
axes[2].set_title("Equity–Bond Correlation\nper Regime", fontsize=11, fontweight="bold")
axes[2].set_ylabel("Correlation")
axes[2].set_ylim(-1, 1)

for ax in axes:
    ax.grid(axis="y", alpha=0.3)
    ax.spines[["top", "right"]].set_visible(False)
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=15, ha="right")
    ax.tick_params(axis="x", labelsize=8)

fig.suptitle("Regime Characteristics — Training Set (2015–2023)",
             fontsize=13, fontweight="bold", y=1.02)
plt.tight_layout()
fig.savefig(os.path.join(OUTPUT_DIR, "chart_regime_characteristics.png"),
            dpi=150, bbox_inches="tight")
plt.close()
print("       OK - chart_regime_characteristics.png")


# ── Chart 4: Cumulative Returns ──────────────────────────────────────────
fig, axes = plt.subplots(2, 1, figsize=(14, 9),
                          gridspec_kw={"height_ratios": [2.5, 1]},
                          sharex=True)

# Top: indexed cumulative return (base = 100) — avoids flat-line problem
# caused by large absolute dollar values compressing the y-axis range
indexed_strat = portfolio_df["Portfolio_Value"] / portfolio_df["Portfolio_Value"].iloc[0] * 100
indexed_bench = portfolio_df["Benchmark_Value"] / portfolio_df["Benchmark_Value"].iloc[0] * 100

ax0 = axes[0]
ax0.plot(portfolio_df.index, indexed_strat,
         color="#2ECC71", linewidth=2.0, label="Regime-Switching Strategy")
ax0.plot(portfolio_df.index, indexed_bench,
         color="#95A5A6", linewidth=1.5, linestyle="--", label="60/40 Buy-and-Hold")

# Shade regimes using axvspan — avoids y-axis scale corruption from fill_between
for r, color in REGIME_COLORS.items():
    in_regime = False
    start_date = None
    regime_series = master["Regime"].reindex(portfolio_df.index)
    for date, reg in regime_series.items():
        if reg == r and not in_regime:
            in_regime = True
            start_date = date
        elif reg != r and in_regime:
            ax0.axvspan(start_date, date, alpha=0.06, color=color, zorder=0)
            in_regime = False
    if in_regime and start_date is not None:
        ax0.axvspan(start_date, portfolio_df.index[-1],
                    alpha=0.06, color=color, zorder=0)

ax0.set_title("Regime-Switching Strategy vs 60/40 Buy-and-Hold (Indexed, Base = 100)",
              fontsize=13, fontweight="bold")
ax0.set_ylabel("Indexed Value (Start = 100)")
ax0.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f"{x:.0f}"))
ax0.legend(loc="upper left", fontsize=9)
ax0.grid(alpha=0.3)
annotate_stress(ax0)

# Add final value annotations showing both index value and actual dollar value
final_pv = portfolio_df["Portfolio_Value"].iloc[-1]
final_bv = portfolio_df["Benchmark_Value"].iloc[-1]
final_idx_s = indexed_strat.iloc[-1]
final_idx_b = indexed_bench.iloc[-1]
ax0.annotate(f"{final_idx_s:.0f}  (${final_pv:,.0f})",
             xy=(portfolio_df.index[-1], final_idx_s),
             xytext=(-110, 10), textcoords="offset points",
             fontsize=9, color="#27AE60", fontweight="bold")
ax0.annotate(f"{final_idx_b:.0f}  (${final_bv:,.0f})",
             xy=(portfolio_df.index[-1], final_idx_b),
             xytext=(-110, -18), textcoords="offset points",
             fontsize=9, color="#7F8C8D")

# Bottom: drawdown comparison
ax1 = axes[1]
strat_dd = (portfolio_df["Portfolio_Value"] /
            portfolio_df["Portfolio_Value"].cummax() - 1)
bench_dd = (portfolio_df["Benchmark_Value"] /
            portfolio_df["Benchmark_Value"].cummax() - 1)

ax1.fill_between(portfolio_df.index, strat_dd, 0,
                 alpha=0.5, color="#E74C3C", label="Strategy Drawdown")
ax1.fill_between(portfolio_df.index, bench_dd, 0,
                 alpha=0.3, color="#95A5A6", label="60/40 Drawdown")
ax1.plot(portfolio_df.index, strat_dd, color="#E74C3C", linewidth=0.8)
ax1.plot(portfolio_df.index, bench_dd, color="#7F8C8D", linewidth=0.8, linestyle="--")
ax1.set_ylabel("Drawdown")
pct_fmt(ax1)
ax1.legend(loc="lower right", fontsize=8)
add_year_grid(ax1)
annotate_stress(ax1)

plt.tight_layout()
fig.savefig(os.path.join(OUTPUT_DIR, "chart_cumulative_returns.png"),
            dpi=150, bbox_inches="tight")
plt.close()
print("       OK - chart_cumulative_returns.png")


# ── Chart 5: Portfolio Weight Evolution ──────────────────────────────────
# Reconstruct daily weights by re-applying the soft allocation formula
weight_records = []
for i, (date, row) in enumerate(master.iterrows()):
    posterior = np.array([row.get(f"P_Regime{r}", 0.0) for r in range(n_regimes)])
    if np.isnan(posterior).any():
        posterior = np.zeros(n_regimes)
        posterior[1] = 1.0  # default to Normal
    w = compute_soft_weights(posterior)
    w["Date"] = date
    weight_records.append(w)

weight_df = pd.DataFrame(weight_records).set_index("Date")

# Group into equity vs bond vs gold for cleaner chart
weight_df["Total_Equity"] = weight_df[EQUITY_TICKERS].sum(axis=1)
weight_df["Total_Bond"]   = weight_df[BOND_TICKERS].sum(axis=1)
weight_df["Total_Gold"]   = weight_df[GOLD_TICKERS].sum(axis=1)

fig, ax = plt.subplots(figsize=(14, 5))
ax.stackplot(weight_df.index,
             weight_df["Total_Equity"],
             weight_df["Total_Bond"],
             weight_df["Total_Gold"],
             labels=["Equity (XIU+VFV+XEF)", "Bond (XBB)", "Gold (CGL)"],
             colors=["#3498DB", "#F39C12", "#F1C40F"],
             alpha=0.85)
ax.set_title("Portfolio Weight Allocation Over Time (Regime-Switching Strategy)",
             fontsize=13, fontweight="bold")
ax.set_ylabel("Portfolio Weight")
pct_fmt(ax)
ax.set_ylim(0, 1)
ax.legend(loc="lower left", fontsize=9, ncol=3)
add_year_grid(ax)
annotate_stress(ax)
plt.tight_layout()
fig.savefig(os.path.join(OUTPUT_DIR, "chart_portfolio_weights.png"),
            dpi=150, bbox_inches="tight")
plt.close()
print("       OK - chart_portfolio_weights.png")


# ── Chart 6: Drawdown Comparison (standalone) ────────────────────────────
fig, ax = plt.subplots(figsize=(14, 5))
ax.fill_between(portfolio_df.index, strat_dd * 100, 0,
                alpha=0.55, color="#E74C3C", label="Regime-Switching Strategy")
ax.fill_between(portfolio_df.index, bench_dd * 100, 0,
                alpha=0.35, color="#95A5A6", label="60/40 Buy-and-Hold")
ax.plot(portfolio_df.index, strat_dd * 100, color="#C0392B", linewidth=1.0)
ax.plot(portfolio_df.index, bench_dd * 100, color="#7F8C8D",
        linewidth=1.0, linestyle="--")

# Annotate max drawdowns
strat_max_dd_date = strat_dd.idxmin()
bench_max_dd_date = bench_dd.idxmin()
ax.annotate(f"Strategy max DD: {strat_dd.min():.1%}",
            xy=(strat_max_dd_date, strat_dd.min() * 100),
            xytext=(30, -20), textcoords="offset points",
            fontsize=9, color="#C0392B",
            arrowprops=dict(arrowstyle="->", color="#C0392B", lw=1.0))
ax.annotate(f"60/40 max DD: {bench_dd.min():.1%}",
            xy=(bench_max_dd_date, bench_dd.min() * 100),
            xytext=(30, 10), textcoords="offset points",
            fontsize=9, color="#7F8C8D",
            arrowprops=dict(arrowstyle="->", color="#7F8C8D", lw=1.0))

ax.set_title("Drawdown Comparison: Strategy vs 60/40 Buy-and-Hold",
             fontsize=13, fontweight="bold")
ax.set_ylabel("Drawdown (%)")
ax.set_ylim(min(strat_dd.min(), bench_dd.min()) * 100 * 1.2, 2)
ax.legend(loc="lower right", fontsize=9)
add_year_grid(ax)
annotate_stress(ax)
plt.tight_layout()
fig.savefig(os.path.join(OUTPUT_DIR, "chart_drawdown.png"),
            dpi=150, bbox_inches="tight")
plt.close()
print("       OK - chart_drawdown.png")

"""### Summary"""

print("\n[8/8]  Saving summary report ...")

report_path = os.path.join(OUTPUT_DIR, "phase34_summary.txt")
with open(report_path, "w") as f:
    f.write("REGIME-SWITCHING ASSET ALLOCATION — PHASE 3 & 4 REPORT\n")
    f.write(f"Generated : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write("=" * 65 + "\n\n")

    f.write("PHASE 3 — TRANSITION PROBABILITIES\n")
    f.write(trans_df.to_string() + "\n\n")
    f.write("Expected Regime Duration (days):\n")
    for r in range(n_regimes):
        stay = trans_matrix[r, r]
        avg_days = 1 / (1 - stay) if stay < 1 else np.inf
        f.write(f"  {REGIME_LABELS[r]:<26}: {avg_days:.1f} days\n")

    f.write(f"\nT^{FORWARD_DAYS} (30-day ahead transition matrix):\n")
    t30_df = pd.DataFrame(T_power,
                          index=[REGIME_LABELS[r] for r in range(n_regimes)],
                          columns=[REGIME_LABELS[r] for r in range(n_regimes)])
    f.write(t30_df.to_string() + "\n\n")

    f.write("PHASE 3 — REGIME CHARACTERISTICS (Training Set)\n")
    f.write(f"  {'Regime':<26}  {'Days':>5}  {'%Time':>6}  "
            f"{'Mkt Vol':>7}  {'EQ Ret':>7}  {'Bond Ret':>8}  "
            f"{'EQ-Bnd Corr':>11}\n")
    f.write("  " + "-" * 78 + "\n")
    for r in range(n_regimes):
        if r not in char_df.index:
            continue
        row = char_df.loc[r]
        f.write(f"  {REGIME_LABELS[r]:<26}  "
                f"{row['N_Days']:>5}  "
                f"{row['Pct_Time']:>6.1%}  "
                f"{row.get('Avg_Market_Vol', np.nan):>7.1%}  "
                f"{row.get('Equity_AnnRet', np.nan):>+7.1%}  "
                f"{row.get('Bond_AnnRet', np.nan):>+8.1%}  "
                f"{row.get('EQ_Bond_Corr', np.nan):>11.4f}\n")

    f.write("\nPHASE 3 — FORWARD-LOOKING SIGNAL (30-day crisis probability)\n")
    f.write(f"  COVID window peak   : "
            f"{signals.loc['2020-02-01':'2020-05-31', 'P_Crisis_30d'].max():.1%}\n")
    f.write(f"  2022 window peak    : "
            f"{signals.loc['2022-01-01':'2022-12-31', 'P_Crisis_30d'].max():.1%}\n")

    f.write("\nPHASE 4 — TARGET WEIGHTS BY REGIME\n")
    for r in range(n_regimes):
        f.write(f"  {REGIME_LABELS[r]}:\n")
        for ticker, w in TARGET_WEIGHTS[r].items():
            f.write(f"    {ticker:<12}: {w:.0%}\n")

    f.write(f"\nPHASE 4 — BACKTEST RESULTS (${INITIAL_CAPITAL:,.0f} initial capital)\n")
    f.write(f"  {'Metric':<22}  {'Strategy':>10}  {'60/40 BH':>10}  {'Difference':>12}\n")
    f.write("  " + "-" * 60 + "\n")
    for _, row in results_df.iterrows():
        s = row["Strategy"]
        b = row["Benchmark_60_40"]
        d = row["Difference"]
        fmt = "{:>+10.1%}" if "Return" in row["Metric"] or "Drawdown" in row["Metric"] \
              or "Rate" in row["Metric"] else "{:>10.3f}"
        dfmt = "{:>+12.1%}" if "Return" in row["Metric"] or "Drawdown" in row["Metric"] \
               or "Rate" in row["Metric"] else "{:>+12.3f}"
        try:
            f.write(f"  {row['Metric']:<22}  {fmt.format(s)}  {fmt.format(b)}  "
                    f"{dfmt.format(d)}\n")
        except (ValueError, TypeError):
            f.write(f"  {row['Metric']:<22}  {str(s):>10}  {str(b):>10}  {str(d):>12}\n")

    f.write(f"\n  Rebalancing events : {n_rebalances}\n")
    f.write(f"  Total costs        : ${total_costs:.2f}\n")
    f.write(f"  Cost as % of final : {net_cost_impact:.3%}\n")

print(f"       OK - phase34_summary.txt")